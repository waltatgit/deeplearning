{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
    "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
    "# ATTENTION: Please use the provided epoch values when training.\n",
    "\n",
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [],
   "source": [
    "path_inception = f\"{getcwd()}/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = path_inception\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None)\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "    # Your Code Here\n",
    "    layer.trainable = False\n",
    "\n",
    "# Print the model summary\n",
    "#pre_trained_model.summary()\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFsUlwdfs_wg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>0.97):\n",
    "      print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 74, 74, 32)   864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 74, 74, 32)   96          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 74, 74, 32)   0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 72, 72, 32)   9216        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 72, 72, 32)   96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 72, 72, 32)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 72, 72, 64)   18432       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 72, 72, 64)   192         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 72, 72, 64)   0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 35, 35, 80)   240         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 35, 35, 80)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 33, 33, 192)  138240      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 33, 33, 192)  576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 33, 33, 192)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 16, 16, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 16, 16, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 16, 16, 96)   55296       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 16, 16, 48)   144         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 16, 16, 96)   288         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 16, 16, 48)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 16, 16, 96)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 16, 16, 64)   76800       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 16, 16, 96)   82944       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 16, 16, 64)   192         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 16, 16, 64)   192         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 16, 16, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 16, 16, 32)   96          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 16, 16, 64)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 16, 16, 64)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 16, 16, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 16, 16, 32)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_193[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 16, 16, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 16, 16, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 16, 16, 96)   55296       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 16, 16, 48)   144         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 16, 16, 96)   288         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 16, 16, 48)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 16, 16, 96)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 16, 16, 64)   76800       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 16, 16, 96)   82944       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 16, 16, 64)   192         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 16, 16, 64)   192         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 16, 16, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 16, 16, 64)   192         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 16, 16, 64)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 16, 16, 64)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 16, 16, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 16, 16, 64)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 16, 16, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 16, 16, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 16, 16, 96)   55296       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 16, 16, 48)   144         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 16, 16, 96)   288         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 16, 16, 48)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 16, 16, 96)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 16, 16, 64)   76800       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 16, 16, 96)   82944       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 16, 16, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 16, 16, 64)   192         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 16, 16, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 16, 16, 64)   192         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 16, 16, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 16, 16, 64)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 16, 16, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 16, 16, 64)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 16, 16, 64)   192         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 16, 16, 64)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 16, 16, 96)   55296       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 16, 16, 96)   288         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 16, 16, 96)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 7, 7, 96)     82944       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 7, 7, 384)    1152        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 7, 7, 96)     288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 7, 7, 384)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 7, 7, 96)     0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_214[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 7, 7, 128)    384         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 7, 7, 128)    0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 7, 7, 128)    114688      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 7, 7, 128)    384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 7, 7, 128)    114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 7, 7, 128)    384         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 7, 7, 128)    384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 7, 7, 128)    0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 7, 7, 128)    0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 7, 7, 128)    114688      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 7, 7, 128)    114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 7, 7, 128)    384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 7, 7, 128)    384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 7, 7, 128)    0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 7, 7, 128)    0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 7, 7, 192)    172032      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 7, 7, 192)    172032      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 7, 7, 192)    576         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 7, 7, 192)    576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 7, 7, 192)    576         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 7, 7, 192)    576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 7, 7, 192)    0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 7, 7, 192)    0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 7, 7, 192)    0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 7, 7, 192)    0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 7, 7, 160)    480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 7, 7, 160)    0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 7, 7, 160)    179200      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 7, 7, 160)    480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 7, 7, 160)    0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 7, 7, 160)    179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 7, 7, 160)    480         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 7, 7, 160)    480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 7, 7, 160)    0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 7, 7, 160)    0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 7, 7, 160)    179200      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 7, 7, 160)    179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 7, 7, 160)    480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 7, 7, 160)    480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 7, 7, 160)    0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 7, 7, 160)    0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 7, 7, 192)    215040      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 7, 7, 192)    215040      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 7, 7, 192)    576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 7, 7, 192)    576         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 7, 7, 192)    576         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 7, 7, 192)    576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 7, 7, 192)    0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 7, 7, 192)    0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 7, 7, 192)    0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 7, 7, 192)    0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_228[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 activation_236[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 7, 7, 160)    480         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 7, 7, 160)    0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 7, 7, 160)    179200      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 7, 7, 160)    480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 7, 7, 160)    0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 7, 7, 160)    179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 7, 7, 160)    480         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 7, 7, 160)    480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 7, 7, 160)    0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 7, 7, 160)    0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 7, 7, 160)    179200      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 7, 7, 160)    179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 7, 7, 160)    480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 7, 7, 160)    480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 7, 7, 160)    0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 7, 7, 160)    0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 7, 7, 192)    215040      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 7, 7, 192)    215040      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 7, 7, 192)    576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 7, 7, 192)    576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 7, 7, 192)    576         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 7, 7, 192)    576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 7, 7, 192)    0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 7, 7, 192)    0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 7, 7, 192)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 7, 7, 192)    0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_238[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "                                                                 activation_246[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 7, 7, 192)    576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 7, 7, 192)    0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 7, 7, 192)    258048      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 7, 7, 192)    576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 7, 7, 192)    0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 7, 7, 192)    258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 7, 7, 192)    576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 7, 7, 192)    576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 7, 7, 192)    0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 7, 7, 192)    0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 7, 7, 192)    258048      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 7, 7, 192)    258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 7, 7, 192)    576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 7, 7, 192)    576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 7, 7, 192)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 7, 7, 192)    0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 7, 7, 192)    258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 7, 7, 192)    258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 7, 7, 192)    576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 7, 7, 192)    576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 7, 7, 192)    576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 7, 7, 192)    576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 7, 7, 192)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 7, 7, 192)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 7, 7, 192)    0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 7, 7, 192)    0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1024)         38536192    flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            1025        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
    "\n",
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnL_IQ8knWA"
   },
   "outputs": [],
   "source": [
    "# Get the Horse or Human dataset\n",
    "path_horse_or_human = f\"{getcwd()}/../tmp2/horse-or-human.zip\"\n",
    "# Get the Horse or Human Validation dataset\n",
    "path_validation_horse_or_human = f\"{getcwd()}/../tmp2/validation-horse-or-human.zip\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree('/tmp')\n",
    "local_zip = path_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = path_validation_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9okX7_ovskI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "train_horses_dir = '/tmp/training/horses/'\n",
    "train_humans_dir = '/tmp/training/humans/'\n",
    "validation_horses_dir = '/tmp/validation/horses'\n",
    "validation_humans_dir = '/tmp/validation/humans'\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir)\n",
    "train_humans_fnames = os.listdir(train_humans_dir)\n",
    "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print(len(train_humans_fnames))\n",
    "print(len(validation_horses_fnames))\n",
    "print(len(validation_horses_fnames))\n",
    "\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary', \n",
    "                                                    target_size = (150, 150)) \n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                          batch_size  = 20,\n",
    "                                                          class_mode  = 'binary', \n",
    "                                                          target_size = (150, 150))\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\n",
      "Reached 97.0% accuracy so cancelling training!\n",
      "52/52 - 44s - loss: 0.0600 - accuracy: 0.9766 - val_loss: 0.0396 - val_accuracy: 0.9844\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 97% accuracy\n",
    "\n",
    "#callbacks = # Your Code Here\n",
    "history = model.fit_generator(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            epochs = 5,\n",
    "            verbose = 2, callbacks=[myCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This will free up resources for your fellow learners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.session.delete();\n",
    "window.onbeforeunload = null\n",
    "setTimeout(function() { window.close(); }, 1000);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "csg1x",
   "launcher_item_id": "GpKYz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
